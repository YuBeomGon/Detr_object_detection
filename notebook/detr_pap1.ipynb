{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "# from tqdm import tqdm\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from xml.etree.ElementTree import parse\n",
    "# from pascal_voc_writer import Writer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#CV\n",
    "import cv2\n",
    "\n",
    "################# DETR FUCNTIONS FOR LOSS######################## \n",
    "import sys\n",
    "sys.path.extend(['./detr/'])\n",
    "\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "################################################################\n",
    "\n",
    "#Albumenatations\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "#Glob\n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['./util/'])\n",
    "from data_parser import *\n",
    "from image_prepro import *\n",
    "# from torchvision import transforms\n",
    "\n",
    "from visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install opencv-python\n",
    "# !pip3 install tqdm\n",
    "# !pip3 install sklearn\n",
    "# !pip3 install albumentations\n",
    "# !pip3 install pillow\n",
    "# !pip3 install pandas\n",
    "# !pip3 install torch\n",
    "# !pip3 install torchvision\n",
    "# !pip3 install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !conda install -y pytorch torchvision cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/detr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/home/beomgon/Object_Detection/Dataset'\n",
    "df = pd.DataFrame(columns=['label', 'org_label', 'bbox', 'xmin','ymin','xmax','ymax','width','height', 'file_name', 'path'])\n",
    "# df = pd.DataFrame(columns=['class','bbox', 'path'])\n",
    "data_list = []\n",
    "for dir_name in ['SS', 'SS2']:\n",
    "    dpath = os.path.join(src_path, dir_name)\n",
    "#     print(dpath)\n",
    "    dir_lists = os.listdir(dpath) \n",
    "#     print(dir_lists)\n",
    "    \n",
    "    for dir_list in dir_lists :\n",
    "        dpath2 = os.path.join(dpath, dir_list)\n",
    "        xml_list = [os.path.join(dpath2, d) for d in os.listdir(dpath2) if d.endswith(\".xml\")]\n",
    "#         print(xml_list)\n",
    "        for xml_path in xml_list :\n",
    "            parser = XMLParser(xml_path)\n",
    "            if (parser.height, parser.width) not in parser.rejection_size:  \n",
    "                filename = parser.file_name\n",
    "                for obj in parser.objects :\n",
    "    #                     obj_class = obj[0]\n",
    "    #                     if obj_class in rej_table :\n",
    "    #                         continue\n",
    "    #                     print(obj)\n",
    "                    img_path = '/'.join((xml_path.split('/')[:-1])) + '/' + filename\n",
    "    #                 img_path = re.sub('xml', 'jpg', xml_path)\n",
    "    # #                     print(img_path)\n",
    "                    obj.append(parser.width)\n",
    "                    obj.append(parser.height)\n",
    "                    obj.append(parser.file_name)\n",
    "                    obj.append(img_path)\n",
    "                    data_list.append(obj)\n",
    "    # #                     print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>org_label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>file_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carcinoma</td>\n",
       "      <td>Suamous cell carcinoma</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>[2061, 1051, 2178, 1175]</td>\n",
       "      <td>2061</td>\n",
       "      <td>1051</td>\n",
       "      <td>2178</td>\n",
       "      <td>1175</td>\n",
       "      <td>20200623_100015.jpg</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>[1945, 870, 2024, 941]</td>\n",
       "      <td>1945</td>\n",
       "      <td>870</td>\n",
       "      <td>2024</td>\n",
       "      <td>941</td>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>[2400, 947, 2484, 1020]</td>\n",
       "      <td>2400</td>\n",
       "      <td>947</td>\n",
       "      <td>2484</td>\n",
       "      <td>1020</td>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>[2209, 845, 2307, 912]</td>\n",
       "      <td>2209</td>\n",
       "      <td>845</td>\n",
       "      <td>2307</td>\n",
       "      <td>912</td>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>[2056, 811, 2144, 866]</td>\n",
       "      <td>2056</td>\n",
       "      <td>811</td>\n",
       "      <td>2144</td>\n",
       "      <td>866</td>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label               org_label  width  height                      bbox  \\\n",
       "0  Carcinoma  Suamous cell carcinoma   4032    1960  [2061, 1051, 2178, 1175]   \n",
       "1       HSIL                    HSIL   4032    1960    [1945, 870, 2024, 941]   \n",
       "2       HSIL                    HSIL   4032    1960   [2400, 947, 2484, 1020]   \n",
       "3       HSIL                    HSIL   4032    1960    [2209, 845, 2307, 912]   \n",
       "4       HSIL                    HSIL   4032    1960    [2056, 811, 2144, 866]   \n",
       "\n",
       "   xmin  ymin  xmax  ymax            file_name  \\\n",
       "0  2061  1051  2178  1175  20200623_100015.jpg   \n",
       "1  1945   870  2024   941  20200420_100401.jpg   \n",
       "2  2400   947  2484  1020  20200420_100401.jpg   \n",
       "3  2209   845  2307   912  20200420_100401.jpg   \n",
       "4  2056   811  2144   866  20200420_100401.jpg   \n",
       "\n",
       "                                                path  \n",
       "0  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "1  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "2  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "3  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "4  /home/beomgon/Object_Detection/Dataset/SS/06/2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_list,columns=['label', 'org_label', 'bbox', 'xmin','ymin','xmax','ymax','width','height', 'file_name', 'path'])\n",
    "df = df[['label', 'org_label', 'width','height', 'bbox', 'xmin','ymin','xmax','ymax', 'file_name', 'path']]\n",
    "# print(df.head())\n",
    "# df = df.reset_index(drop=True)\n",
    "# df.drop(columns = ['index'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #     width in albumentation is x asix, so ymax - xmax\n",
    "# # df = df[['label', 'org_label', 'width','height', 'bbox', 'ymin', 'xmin','ymax','xmax', 'file_name', 'path']]\n",
    "# # df.drop(columns=['bbox'], inplace=True)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df.width)\n",
    "# set(df.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator\n",
    "\n",
    "# width = []\n",
    "# height = []\n",
    "# xmax_list = list(df.xmax)\n",
    "# xmin_list = list(df.xmin.apply(lambda x : -1*x))\n",
    "# ymax_list = list(df.ymax)\n",
    "# ymin_list = list(df.ymin.apply(lambda x : -1*x))\n",
    "\n",
    "# height = list(map(operator.add, xmax_list, xmin_list))\n",
    "# width = list(map(operator.add, ymax_list, ymin_list))\n",
    "# df['box_width'] = width\n",
    "# df['box_height'] = height\n",
    "# df['x_min'] = list(df.ymin)\n",
    "# df['y_min'] = list(df.xmin)\n",
    "# df.drop(columns=['bbox', 'xmax', 'ymax', 'xmin', 'ymin'], inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop NA cell\n",
    "# print((len(df)))\n",
    "# df.label = df.label.apply(lambda x : np.nan if x == '' else x)\n",
    "# df.dropna(subset=['label'], inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# print((len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_to_id(x) :\n",
    "#     x = str(x)\n",
    "#     if x == 'ASCUS' :\n",
    "#         return 0\n",
    "#     elif x == 'Carcinoma' :\n",
    "#         return 1\n",
    "#     elif x == 'HSIL' :\n",
    "#         return 2\n",
    "#     elif x == 'LSIL' :\n",
    "#         return 3\n",
    "#     elif x == 'Normal' :\n",
    "#         return 4\n",
    "    \n",
    "# df['label_id'] = df.label.apply(lambda x : label_to_id(x))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['file_name', 'width', 'height', 'x_min', 'y_min', 'box_width', 'box_height', 'org_label', 'label', 'label_id',  'path']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('df.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>org_label</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200623_100015.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>1051</td>\n",
       "      <td>2061</td>\n",
       "      <td>124</td>\n",
       "      <td>117</td>\n",
       "      <td>Suamous cell carcinoma</td>\n",
       "      <td>Carcinoma</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>870</td>\n",
       "      <td>1945</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>947</td>\n",
       "      <td>2400</td>\n",
       "      <td>73</td>\n",
       "      <td>84</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>845</td>\n",
       "      <td>2209</td>\n",
       "      <td>67</td>\n",
       "      <td>98</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200420_100401.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>811</td>\n",
       "      <td>2056</td>\n",
       "      <td>55</td>\n",
       "      <td>88</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/06/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name  width  height  x_min  y_min  box_width  box_height  \\\n",
       "0  20200623_100015.jpg   4032    1960   1051   2061        124         117   \n",
       "1  20200420_100401.jpg   4032    1960    870   1945         71          79   \n",
       "2  20200420_100401.jpg   4032    1960    947   2400         73          84   \n",
       "3  20200420_100401.jpg   4032    1960    845   2209         67          98   \n",
       "4  20200420_100401.jpg   4032    1960    811   2056         55          88   \n",
       "\n",
       "                org_label      label  label_id  \\\n",
       "0  Suamous cell carcinoma  Carcinoma         1   \n",
       "1                    HSIL       HSIL         2   \n",
       "2                    HSIL       HSIL         2   \n",
       "3                    HSIL       HSIL         2   \n",
       "4                    HSIL       HSIL         2   \n",
       "\n",
       "                                                path  \n",
       "0  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "1  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "2  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "3  /home/beomgon/Object_Detection/Dataset/SS/06/2...  \n",
       "4  /home/beomgon/Object_Detection/Dataset/SS/06/2...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = list(range(len(df)))\n",
    "# # images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "def get_data() :\n",
    "    data  = df_data.get_group(img_id)\n",
    "    labels = data.label.values\n",
    "#     source = data.source.values\n",
    "#     source = np.unique(data.source.values)\n",
    "#     assert len(source)==1, 'corrupted data: %s image_id has many sources: %s' %(img_id,source)\n",
    "#     source=source[0]\n",
    "    boxes = data[['x_min','y_min','box_width','box_height']].values\n",
    "#     boxes = list(data.bbox)\n",
    "    label_id = data.label_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18824"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_data = df.groupby('file_name')\n",
    "# images = list(set(df.file_name))\n",
    "df_data = df.groupby('path')\n",
    "images = list(set(df.path))\n",
    "len(images)\n",
    "# len(df_data)\n",
    "# len(df_data.groups)\n",
    "# df_data.get_group('20200420_100401.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(img_id):\n",
    "    if img_id not in df_data.groups:\n",
    "        return dict(image_id=img_id, source='', boxes=list())\n",
    "    \n",
    "    data  = df_data.get_group(img_id)\n",
    "    labels = data.label.values\n",
    "#     source = data.source.values\n",
    "#     source = np.unique(data.source.values)\n",
    "#     assert len(source)==1, 'corrupted data: %s image_id has many sources: %s' %(img_id,source)\n",
    "#     source=source[0]\n",
    "    boxes = data[['x_min','y_min','box_width','box_height']].values\n",
    "#     boxes = list(data.bbox)\n",
    "    label_id = data.label_id.values\n",
    "    return dict(image_id = img_id, labels=labels, label_id=label_id, boxes = boxes)\n",
    "\n",
    "image_list = [get_data(img_id) for img_id in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOX_COLOR = (255, 0, 0) # Red\n",
    "# TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "# def visualize_bbox(img, bbox, w=0, h=0, color=BOX_COLOR, thickness=2, IsNormalize=True):\n",
    "#     \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "#     print('IsNormalize', IsNormalize)\n",
    "#     if IsNormalize  :\n",
    "#         x, y, width, height = bbox\n",
    "\n",
    "#         x_min = int((x - width)*w)\n",
    "#         y_min = int((y - height)*h)\n",
    "#         x_max = int((x + width)*w)\n",
    "#         y_max = int((y + height)*h)   \n",
    "        \n",
    "#     else :\n",
    "# #         print(type(bbox))\n",
    "# #         bbox[:,2:] /= 2\n",
    "# #         bbox[:,:2] += bbox[:,2:] \n",
    "#         x_min, y_min, x_max, y_max = list(map(int, bbox))\n",
    "#     print(x_min, y_min, x_max, y_max)\n",
    "\n",
    "#     img = cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    \n",
    "# #     ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "# #     cv2.rectangle(img, (y_min - int(1.3 * text_height), x_min ), (y_min, x_min + text_width ), BOX_COLOR, -1)\n",
    "# #     cv2.putText(\n",
    "# #         img,\n",
    "# #         text=class_name,\n",
    "# #         org=(x_min, y_min - int(0.3 * text_height)),\n",
    "# #         fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "# #         fontScale=0.35, \n",
    "# #         color=TEXT_COLOR, \n",
    "# #         lineType=cv2.LINE_AA,\n",
    "# #     )\n",
    "#     return img\n",
    "\n",
    "# def visualize(image, bboxes, w=0, h=0, category_ids=None, category_id_to_name=None, IsNormalize=True ):\n",
    "#     if type(image) is np.ndarray :\n",
    "#         img = image.copy()\n",
    "#     else : # pytorch tensor\n",
    "#         img = image.clone().data.cpu().numpy()\n",
    "#     print(type(img))\n",
    "# #     print(IsNormalize)\n",
    "# #     for bbox, category_id in zip(bboxes, category_ids):\n",
    "# #         class_name = category_id_to_name[category_id]\n",
    "# #         print(class_name)\n",
    "#     for bbox in bboxes :\n",
    "# #         print(bbox)\n",
    "#         img = visualize_bbox(img, bbox, w, h, IsNormalize=IsNormalize )\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(image_list[0])\n",
    "# Number = 282\n",
    "# path = image_list[Number]['image_id'] \n",
    "# boxes = image_list[Number]['boxes']\n",
    "# print(path)\n",
    "# new_bboxes = []\n",
    "# for i in boxes :\n",
    "#     xmin, ymin, box_width, box_height = i\n",
    "#     new_bboxes.append([xmin, ymin, xmin + box_width, ymin + box_height])\n",
    "# # print(new_bboxes)\n",
    "# # print(path)\n",
    "# image = cv2.imread(path)\n",
    "# # print(type(image))\n",
    "# w, h, _ = image.shape\n",
    "# # print(w, h)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.flip(image, 1)\n",
    "\n",
    "# visualize(image, new_bboxes, w, h, IsNormalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = A.augmentations.bbox_utils.normalize_bboxes([[634, 934, 128, 75]],rows=1200,cols=1000)\n",
    "# boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_transforms():\n",
    "#     return A.Compose([\n",
    "#         A.CenterCrop(1600,1600, True,1),\n",
    "#         A.RandomCrop(height=800, width=800, p=0.5),\n",
    "#         A.Resize(height=512, width=512, p=1),\n",
    "\n",
    "#         A.OneOf([\n",
    "#         A.HorizontalFlip(p=0.9),\n",
    "#         A.VerticalFlip(p=0.9),\n",
    "#         A.RandomRotate90(p=0.9),        \n",
    "#         ], p=1),\n",
    "#         A.GaussNoise(p=0.5),   \n",
    "#             A.Normalize(max_pixel_value=1),\n",
    "#             #A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),\n",
    "#             ToTensorV2(p=1.0)\n",
    "#         ], \n",
    "#         p=1.0,         \n",
    "#         bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "#         )\n",
    "\n",
    "# def get_valid_transforms():\n",
    "#     return A.Compose([A.Resize(height=512, width=512, p=1.0),\n",
    "#                       A.Normalize(max_pixel_value=1),\n",
    "#                       ToTensorV2(p=1.0),\n",
    "#                       ], \n",
    "#                       p=1.0, \n",
    "#                       bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "#     A.RandomCrop(width=450, height=450),\n",
    "#     A.HorizontalFlip(p=1),\n",
    "    A.CenterCrop(1560,1560, True,1),\n",
    "#     A.RandomCrop(height=800, width=800, p=0.5),\n",
    "#     A.Resize(height=512, width=512, p=1),\n",
    "    A.Resize(height=256, width=256, p=1),\n",
    "    \n",
    "#     A.OneOf([\n",
    "#     A.HorizontalFlip(p=0.9),\n",
    "#     A.VerticalFlip(p=0.9),\n",
    "#     A.RandomRotate90(p=0.9),        \n",
    "#     ], p=1),\n",
    "# #     A.GaussNoise(p=0.5),\n",
    "#     A.OneOf([\n",
    "#     A.OpticalDistortion(p=0.7),\n",
    "#     A.GaussNoise(p=0.7)        \n",
    "#     ], p=1),\n",
    "#     A.RandomBrightnessContrast(p=0.2),\n",
    "#     A.Normalize(max_pixel_value=1),\n",
    "#     ToTensorV2(p=1.0),\n",
    "    A.pytorch.ToTensor(),\n",
    "# ], p=1.0, bbox_params=A.BboxParams(format='pascal_voc', min_area=0, min_visibility=0.5))\n",
    "], p=1.0, bbox_params=A.BboxParams(format='coco', min_area=0, min_visibility=0.5, label_fields=['labels'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number = 160\n",
    "# path = image_list[Number]['image_id'] \n",
    "# boxes = image_list[Number]['boxes']\n",
    "# labels = image_list[Number]['labels']\n",
    "# image = cv2.imread(path)\n",
    "# w, h, _ = image.shape\n",
    "# # print(w, h)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.flip(image, 1)\n",
    "\n",
    "# transformed = transforms(image=image, bboxes=boxes, labels=labels)\n",
    "# transformed_image = transformed['image']\n",
    "# transformed_bboxes = transformed['bboxes']\n",
    "# transformed_class_labels = transformed['labels']\n",
    "# # print(type(transformed_bboxes[0]))\n",
    "# # print(boxes)\n",
    "# # print(transformed_bboxes)\n",
    "# new_bboxes = []\n",
    "# for i in transformed_bboxes :\n",
    "#     xmin, ymin, box_width, box_height = i\n",
    "#     new_bboxes.append([xmin, ymin, xmin + box_width, ymin + box_height])\n",
    "# print(transformed_class_labels)\n",
    "# visualize(transformed_image, new_bboxes,  w, h, IsNormalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR_TRAIN = '../input/global-wheat-detection/train'\n",
    "class WheatDataset(Dataset):\n",
    "    def __init__(self,image_list,transforms=None):\n",
    "        self.images = image_list\n",
    "        self.transforms = transforms\n",
    "        self.img_ids = {x['image_id']:i for i,x in enumerate(image_list)}\n",
    "        \n",
    "    def get_indices(self,img_ids):\n",
    "        return [self.img_ids[x] for x in img_ids]\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        record = self.images[index]\n",
    "        image_id = record['image_id']\n",
    "#         print(image_id)\n",
    "\n",
    "        image = cv2.imread(image_id, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image /= 255.0\n",
    "        \n",
    "        # DETR takes in data in coco format \n",
    "        boxes = record['boxes'] \n",
    "#         print('boxes', boxes)\n",
    "        \n",
    "#         labels =  np.zeros(len(boxes), dtype=np.int32)\n",
    "        labels = record['label_id']\n",
    "#         labels = np.array(labels, dtype=np.int32)\n",
    "#         print('label', type(labels))\n",
    "#         print(labels)\n",
    "#         print(image.shape)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': boxes,\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image  = sample['image']\n",
    "            boxes  = sample['bboxes']\n",
    "            labels = sample['labels']\n",
    "\n",
    "        _,h,w = image.shape\n",
    "        h = w = 256\n",
    "#         print(image.shape)\n",
    "#         print('h', h)\n",
    "#         print('w',w)\n",
    "#         print(h, w)\n",
    "#         print(sample['bboxes'])\n",
    "#         print(type(sample['bboxes'][0]))\n",
    "#         for i in sample['bboxes'][0] :\n",
    "#             if abs(i) > h :\n",
    "#                 print('h', h)\n",
    "#                 print('bbox error')\n",
    "#                 print(sample['bboxes'])\n",
    "# #                 break\n",
    "        boxes = A.augmentations.bbox_utils.normalize_bboxes(sample['bboxes'],rows=h,cols=w)\n",
    "#         print('boxes', boxes)\n",
    "        ## detr uses center_x,center_y,width,height !!\n",
    "        if len(boxes)>0:\n",
    "            boxes = np.array(boxes)\n",
    "            boxes[:,2:] /= 2\n",
    "            boxes[:,:2] += boxes[:,2:]\n",
    "        else:\n",
    "            boxes = np.zeros((0,4))\n",
    "    \n",
    "        target = {}\n",
    "        target['boxes'] = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        \n",
    "        return image, target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WheatDataset(image_list,transforms)\n",
    "# valid_ds = WheatDataset(image_list,get_valid_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image, target, image_id = train_ds[280]\n",
    "# w, h, _ = image.shape\n",
    "# # print(w, h)\n",
    "# boxes = target['boxes']\n",
    "# # print('boxes', boxes)\n",
    "# boxes = A.augmentations.bbox_utils.denormalize_bboxes(boxes,rows=h,cols=w)\n",
    "# # print('boxes', boxes)\n",
    "# new_bboxes = []\n",
    "# for i in boxes :\n",
    "#     x, y, w, h = i\n",
    "#     new_bboxes.append([x-w, y-h, x+w, y+h])\n",
    "# # print(new_bboxes)    \n",
    "# # print('new_bboxes', new_bboxes)\n",
    "# # path = image_id\n",
    "# # image = cv2.imread(path)\n",
    "# # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# # image = cv2.flip(image, 1)\n",
    "# visualize(image, new_bboxes, w, h, IsNormalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "#     torch.utils.data.Subset(train_ds,train_indexes),\n",
    "    train_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    "#     collate_fn=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def DETRModel(num_classes,model_name=model_name):\n",
    "# #     model = torch.hub.load('facebookresearch/detr', model_name, pretrained=False, num_classes=num_classes)\n",
    "# #     def parameter_groups(self):\n",
    "# #         return { 'backbone': [p for n,p in self.named_parameters()\n",
    "# #                               if ('backbone' in n) and p.requires_grad],\n",
    "# #                  'transformer': [p for n,p in self.named_parameters() \n",
    "# #                                  if (('transformer' in n) or ('input_proj' in n)) and p.requires_grad],\n",
    "# #                  'embed': [p for n,p in self.named_parameters()\n",
    "# #                                  if (('class_embed' in n) or ('bbox_embed' in n) or ('query_embed' in n)) \n",
    "# #                            and p.requires_grad]}\n",
    "# #     setattr(type(model),'parameter_groups',parameter_groups)\n",
    "# #     return model\n",
    "\n",
    "# class DETRModel(nn.Module):\n",
    "#     def __init__(self,num_classes=1):\n",
    "#         super(DETRModel,self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "        \n",
    "#         self.model = torch.hub.load('facebookresearch/detr', model_name, pretrained=True)\n",
    "        \n",
    "#         self.out = nn.Linear(in_features=self.model.class_embed.out_features,out_features=num_classes+1)\n",
    "        \n",
    "#     def forward(self,images):\n",
    "#         print(type(images))\n",
    "#         d = self.model(images)\n",
    "#         d['pred_logits'] = self.out(d['pred_logits'])\n",
    "#         return d\n",
    "    \n",
    "#     def parameter_groups(self):\n",
    "#         return { \n",
    "#             'backbone': [p for n,p in self.model.named_parameters()\n",
    "#                               if ('backbone' in n) and p.requires_grad],\n",
    "#             'transformer': [p for n,p in self.model.named_parameters() \n",
    "#                                  if (('transformer' in n) or ('input_proj' in n)) and p.requires_grad],\n",
    "#             'embed': [p for n,p in self.model.named_parameters()\n",
    "#                                  if (('class_embed' in n) or ('bbox_embed' in n) or ('query_embed' in n)) \n",
    "#                            and p.requires_grad],\n",
    "#             'final': self.out.parameters()\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETRModel(nn.Module):\n",
    "    def __init__(self,num_classes,num_queries):\n",
    "        super(DETRModel,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_queries = num_queries\n",
    "        \n",
    "        self.model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "        self.in_features = self.model.class_embed.in_features\n",
    "        \n",
    "        self.model.class_embed = nn.Linear(in_features=self.in_features,out_features=self.num_classes+1)\n",
    "        self.model.num_queries = self.num_queries\n",
    "        \n",
    "    def forward(self,images):\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "seed = 42\n",
    "null_class_coef = 0.5\n",
    "# num_classes = 1\n",
    "num_queries = 100\n",
    "# BATCH_SIZE = 2\n",
    "LR = 5e-5\n",
    "lr_dict = {'backbone':0.1,'transformer':1,'embed':1,'final': 5}\n",
    "EPOCHS = 2\n",
    "max_norm = 0\n",
    "model_name = 'detr_resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DETRModel()\n",
    "# model.parameter_groups().keys()\n",
    "#type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "code taken from github repo detr , 'code present in engine.py'\n",
    "'''\n",
    "\n",
    "# matcher = HungarianMatcher(cost_giou=2,cost_class=1,cost_bbox=5)\n",
    "matcher = HungarianMatcher()\n",
    "\n",
    "weight_dict = {'loss_ce': 1, 'loss_bbox': 5 , 'loss_giou': 2}\n",
    "\n",
    "losses = ['labels', 'boxes', 'cardinality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "criterion = SetCriterion(num_classes, \n",
    "                         matcher, weight_dict, \n",
    "                         eos_coef = null_class_coef, \n",
    "                         losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/beomgon/.cache/torch/hub/facebookresearch_detr_master\n"
     ]
    }
   ],
   "source": [
    "model = DETRModel(num_classes=5, num_queries=num_queries)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda')\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/beomgon/.cache/torch/hub/facebookresearch_detr_master\n",
      "  0%|          | 5/18824 [00:00<26:09, 11.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/beomgon/Object_Detection/Dataset/SS2/05(201020)/20201020_091655.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/06/20200615_140127.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS2/01(200806)/20200826_130028.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/07/20200709_141445.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/04/20200515_140446.png',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/08(200904)/20200724_134428.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/04/20200513_134029.png',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/18824 [00:00<14:21, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/beomgon/Object_Detection/Dataset/SS/01/20200207_134232.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS2/01(200806)/20200810_094336.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/08(200904)/20200724_115113.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/08(200824)/20200715_141147(0).jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/04/20200513_113514.png',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS2/03(200908-10-normal)/20200909_085856.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/04/20200518_105512.png',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/beomgon/Object_Detection/Dataset/SS2/05(201019)/20201019_142735.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/04/20200513_094438.png',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS2/05(201020)/20201020_140507.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS2/06(201026)/20201026_131318.jpg',)\n",
      "('/home/beomgon/Object_Detection/Dataset/SS/08(200827)/20200720_160051.jpg',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-44-96e7d45c91df>\", line 41, in __getitem__\n    sample = self.transforms(**sample)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/core/composition.py\", line 180, in __call__\n    p.preprocess(data)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/core/utils.py\", line 62, in preprocess\n    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction=\"to\")\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/core/utils.py\", line 70, in check_and_convert\n    return self.convert_to_albumentations(data, rows, cols)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 51, in convert_to_albumentations\n    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in convert_bboxes_to_albumentations\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in <listcomp>\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 251, in convert_bbox_to_albumentations\n    check_bbox(bbox)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 328, in check_bbox\n    raise ValueError(\nValueError: Expected y_min for bbox (0.2385, 1.0877777777777777, 0.26825, 1.1594444444444445, 3) to be in the range [0.0, 1.0], got 1.0877777777777777.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d21d96a7a994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#     print(targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     print(targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/detr/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/detr/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-44-96e7d45c91df>\", line 41, in __getitem__\n    sample = self.transforms(**sample)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/core/composition.py\", line 180, in __call__\n    p.preprocess(data)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/core/utils.py\", line 62, in preprocess\n    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction=\"to\")\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/core/utils.py\", line 70, in check_and_convert\n    return self.convert_to_albumentations(data, rows, cols)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 51, in convert_to_albumentations\n    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in convert_bboxes_to_albumentations\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in <listcomp>\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 251, in convert_bbox_to_albumentations\n    check_bbox(bbox)\n  File \"/home/beomgon/anaconda3/envs/detr/lib/python3.8/site-packages/albumentations/augmentations/bbox_utils.py\", line 328, in check_bbox\n    raise ValueError(\nValueError: Expected y_min for bbox (0.2385, 1.0877777777777777, 0.26825, 1.1594444444444445, 3) to be in the range [0.0, 1.0], got 1.0877777777777777.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "criterion = criterion.to(device)\n",
    "model = DETRModel(num_classes=5, num_queries=num_queries)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "criterion.train()\n",
    "tk0 = tqdm(train_data_loader, total=len(train_data_loader),leave=False)\n",
    "log = None\n",
    "device='cuda'\n",
    "for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "#     print(targets)\n",
    "#     print(targets)\n",
    "#     print(images[0].shape)\n",
    "#     print(images[1].shape)\n",
    "#     print(len(images))\n",
    "    print(image_ids)\n",
    "    images = list(image.to(device) for image in images)\n",
    "#     print(images[0])\n",
    "#     print(type(images))\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    \n",
    "    output = model(images)\n",
    "#     print(type(output))\n",
    "#     print(output.keys())\n",
    "#     print(type(output['pred_boxes']))\n",
    "#     print(output['pred_boxes'].size())\n",
    "#     print(output['pred_logits'].size())\n",
    "#     print(type(targets))\n",
    "#     print(targets[0]['boxes'].size())\n",
    "#     print(targets[0].keys())\n",
    "#     print(targets[0]['boxes'].size())\n",
    "#     print(type(targets[0]['labels']))\n",
    "#     print((targets[0]['labels']))\n",
    "# #     print((targets[1]['labels']))\n",
    "#     print(len(targets))\n",
    "\n",
    "    loss_dict = criterion(output, targets)\n",
    "# #     dfsdfs\n",
    "#     if log is None:\n",
    "#         log = {k:AverageMeter() for k in loss_dict}\n",
    "#         log['total_loss'] = AverageMeter()\n",
    "#         log['avg_prec'] = AverageMeter()\n",
    "\n",
    "#     weight_dict = criterion.weight_dict\n",
    "\n",
    "#     total_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     total_loss.backward()\n",
    "\n",
    "# #     if max_norm > 0:\n",
    "# #         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "#     optimizer.step()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>org_label</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41338</th>\n",
       "      <td>20200131_104506.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>243</td>\n",
       "      <td>2056</td>\n",
       "      <td>73</td>\n",
       "      <td>82</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/01/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41339</th>\n",
       "      <td>20200131_104506.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>380</td>\n",
       "      <td>2069</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/01/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41340</th>\n",
       "      <td>20200131_104506.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>1398</td>\n",
       "      <td>2151</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/01/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41341</th>\n",
       "      <td>20200131_104506.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>724</td>\n",
       "      <td>2380</td>\n",
       "      <td>111</td>\n",
       "      <td>76</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/01/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41342</th>\n",
       "      <td>20200131_104506.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>624</td>\n",
       "      <td>2125</td>\n",
       "      <td>63</td>\n",
       "      <td>116</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/01/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_name  width  height  x_min  y_min  box_width  \\\n",
       "41338  20200131_104506.jpg   4032    1960    243   2056         73   \n",
       "41339  20200131_104506.jpg   4032    1960    380   2069         89   \n",
       "41340  20200131_104506.jpg   4032    1960   1398   2151        111   \n",
       "41341  20200131_104506.jpg   4032    1960    724   2380        111   \n",
       "41342  20200131_104506.jpg   4032    1960    624   2125         63   \n",
       "\n",
       "       box_height org_label label  label_id  \\\n",
       "41338          82      HSIL  HSIL         2   \n",
       "41339          98      HSIL  HSIL         2   \n",
       "41340          92      HSIL  HSIL         2   \n",
       "41341          76      HSIL  HSIL         2   \n",
       "41342         116      HSIL  HSIL         2   \n",
       "\n",
       "                                                    path  \n",
       "41338  /home/beomgon/Object_Detection/Dataset/SS/01/2...  \n",
       "41339  /home/beomgon/Object_Detection/Dataset/SS/01/2...  \n",
       "41340  /home/beomgon/Object_Detection/Dataset/SS/01/2...  \n",
       "41341  /home/beomgon/Object_Detection/Dataset/SS/01/2...  \n",
       "41342  /home/beomgon/Object_Detection/Dataset/SS/01/2...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[df['path'] == '/home/beomgon/Object_Detection/Dataset/SS/01/20200131_104506.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>org_label</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23597</th>\n",
       "      <td>20200720_160051.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>1960</td>\n",
       "      <td>841</td>\n",
       "      <td>2055</td>\n",
       "      <td>193</td>\n",
       "      <td>123</td>\n",
       "      <td>Squamous cell carcinoma</td>\n",
       "      <td>Carcinoma</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/08(2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_name  width  height  x_min  y_min  box_width  \\\n",
       "23597  20200720_160051.jpg   4032    1960    841   2055        193   \n",
       "\n",
       "       box_height                org_label      label  label_id  \\\n",
       "23597         123  Squamous cell carcinoma  Carcinoma         1   \n",
       "\n",
       "                                                    path  \n",
       "23597  /home/beomgon/Object_Detection/Dataset/SS/08(2...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['path'] == '/home/beomgon/Object_Detection/Dataset/SS/08(200827)/20200720_160051.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>org_label</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15134</th>\n",
       "      <td>20200513_141113.png</td>\n",
       "      <td>1632</td>\n",
       "      <td>1560</td>\n",
       "      <td>703</td>\n",
       "      <td>805</td>\n",
       "      <td>106</td>\n",
       "      <td>94</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/04/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15135</th>\n",
       "      <td>20200513_141113.png</td>\n",
       "      <td>1632</td>\n",
       "      <td>1560</td>\n",
       "      <td>638</td>\n",
       "      <td>1120</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>HSIL</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/beomgon/Object_Detection/Dataset/SS/04/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_name  width  height  x_min  y_min  box_width  \\\n",
       "15134  20200513_141113.png   1632    1560    703    805        106   \n",
       "15135  20200513_141113.png   1632    1560    638   1120         66   \n",
       "\n",
       "       box_height org_label label  label_id  \\\n",
       "15134          94      HSIL  HSIL         2   \n",
       "15135          52      HSIL  HSIL         2   \n",
       "\n",
       "                                                    path  \n",
       "15134  /home/beomgon/Object_Detection/Dataset/SS/04/2...  \n",
       "15135  /home/beomgon/Object_Detection/Dataset/SS/04/2...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['path'] == '/home/beomgon/Object_Detection/Dataset/SS/04/20200513_141113.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prob = torch.tensor([[0.2369, 0.1790, 0.0908, 0.2360, 0.2573],\n",
    "        [0.1606, 0.1870, 0.0675, 0.3291, 0.2558],\n",
    "        [0.2082, 0.1901, 0.0820, 0.3253, 0.1944],\n",
    "        [0.1048, 0.2228, 0.0688, 0.2919, 0.3117],\n",
    "        [0.1060, 0.1564, 0.0623, 0.3033, 0.3719],\n",
    "        [0.2059, 0.1989, 0.0792, 0.3204, 0.1955],\n",
    "        [0.1749, 0.2239, 0.0955, 0.3518, 0.1540],\n",
    "        [0.1904, 0.2015, 0.0887, 0.3251, 0.1943],\n",
    "        [0.2164, 0.1581, 0.0985, 0.2328, 0.2941],\n",
    "        [0.1147, 0.2238, 0.0754, 0.2984, 0.2877],\n",
    "        [0.1516, 0.2839, 0.0860, 0.3140, 0.1646],\n",
    "        [0.1962, 0.2339, 0.0897, 0.2788, 0.2014],\n",
    "        [0.2014, 0.2448, 0.0873, 0.2672, 0.1993],\n",
    "        [0.1794, 0.2555, 0.0884, 0.3367, 0.1401],\n",
    "        [0.1673, 0.2419, 0.0735, 0.3543, 0.1630],\n",
    "        [0.2082, 0.1528, 0.0913, 0.2985, 0.2492],\n",
    "        [0.1115, 0.1988, 0.0663, 0.2971, 0.3262]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_id = torch.tensor([2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prob[:,tgt_id].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prob[:, [1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python\n",
    "import sys\n",
    "sys.executable\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "m = nn.Conv1d(16,33,3, stride=2)\n",
    "m = m.to('cuda')\n",
    "input = torch.randn(20,16,50)\n",
    "input = input.to('cuda')\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.tensor([1.0, 2.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
